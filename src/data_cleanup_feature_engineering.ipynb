{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Philip/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (15,16,17,22,27,33,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/nfl_plays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GameId', u'GameDate', u'Quarter', u'Minute', u'Second',\n",
       "       u'OffenseTeam', u'DefenseTeam', u'Down', u'ToGo', u'YardLine',\n",
       "       u'Unnamed: 10', u'SeriesFirstDown', u'Unnamed: 12', u'NextScore',\n",
       "       u'Description', u'TeamWin', u'Unnamed: 16', u'Unnamed: 17',\n",
       "       u'SeasonYear', u'Yards', u'Formation', u'PlayType', u'IsRush',\n",
       "       u'IsPass', u'IsIncomplete', u'IsTouchdown', u'PassType', u'IsSack',\n",
       "       u'IsChallenge', u'IsChallengeReversed', u'Challenger', u'IsMeasurement',\n",
       "       u'IsInterception', u'IsFumble', u'IsPenalty', u'IsTwoPointConversion',\n",
       "       u'IsTwoPointConversionSuccessful', u'RushDirection', u'YardLineFixed',\n",
       "       u'YardLineDirection', u'IsPenaltyAccepted', u'PenaltyTeam', u'IsNoPlay',\n",
       "       u'PenaltyType', u'PenaltyYards', u'Unnamed: 45'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove unnamed columns. Most are empty seperators\n",
    "df = df.drop([u'Unnamed: 10', u'Unnamed: 12', u'Unnamed: 16', u'Unnamed: 17', \n",
    "              u'Unnamed: 45','Challenger'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn gamedate into datetimes\n",
    "df['GameDate'] = df['GameDate'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'SeasonYear' with 2013\n",
    "mask = df['SeasonYear'].isnull()\n",
    "df.loc[mask, 'SeasonYear'] = 2013.0\n",
    "\n",
    "mask = df['SeasonYear'] == 0\n",
    "df.loc[mask, 'SeasonYear'] = 2015.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'Yards' with 0.0\n",
    "mask = df['Yards'].isnull()\n",
    "df.loc[mask, 'Yards'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'PlayType' with 'RUSH', they are wildcat plays\n",
    "mask = df['PlayType'].isnull()\n",
    "df.loc[mask, 'PlayType'] = 'RUSH'\n",
    "\n",
    "mask = df['PlayType'] == '0'\n",
    "df.loc[mask, 'PlayType'] = 'PASS'\n",
    "\n",
    "mask = df['PlayType'] == 'UNDER CENTER'\n",
    "df.loc[mask, 'PlayType'] = 'PASS'\n",
    "\n",
    "mask = df['PlayType'] == 'SHOTGUN'\n",
    "df.loc[mask, 'PlayType'] = 'PASS'\n",
    "df.loc[mask, 'IsPass'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace playType two point conversion with rush or pass\n",
    "mask = (df['PlayType'] == 'TWO-POINT CONVERSION') & (df['Description'].str.contains('PASS'))\n",
    "df.loc[mask, 'PlayType'] = 'PASS'\n",
    "df.loc[mask, 'IsPass'] = 1\n",
    "df.loc[mask, 'IsTwoPointConversion'] = 1\n",
    "\n",
    "mask = (df['PlayType'] == 'TWO-POINT CONVERSION') & (df['Description'].str.contains('RUSH'))\n",
    "df.loc[mask, 'PlayType'] = 'RUSH'\n",
    "df.loc[mask, 'IsRush'] = 1\n",
    "df.loc[mask, 'IsTwoPointConversion'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'IsPass' with 0\n",
    "mask = df['IsPass'].isnull()\n",
    "df.loc[mask, 'IsPass'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up IsPass values that should be equal to 1\n",
    "mask = (df['PlayType'] == 'PASS') & (df['IsPass'] != 1)\n",
    "df.loc[mask, 'IsPass'] = 1\n",
    "\n",
    "mask_2 = (df['PlayType'] != 'PASS') & (df['IsPass'] == 1)\n",
    "df.loc[mask_2, 'IsPass'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up IsRush values\n",
    "mask = df['IsRush'] == 'PASS'\n",
    "df.loc[mask, 'IsRush'] = 0\n",
    "\n",
    "mask = df['IsRush'] == '0'\n",
    "df.loc[mask, 'IsRush'] = 0\n",
    "\n",
    "mask = df['IsRush'] == '1'\n",
    "df.loc[mask, 'IsRush'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'IsTouchdown' with 0\n",
    "mask = df['IsTouchdown'].isnull()\n",
    "df.loc[mask, 'IsTouchdown'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'PassType' with 0, also kicks were being missclassified as PASS\n",
    "mask = df['PlayType'] != 'PASS'\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "\n",
    "mask = (df['PlayType'] == 'PASS') & df['Description'].str.contains('KICKS')\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "df.loc[mask, 'PlayType'] = 'PUNT'\n",
    "\n",
    "mask = (df['PlayType'] == 'PASS') & df['Description'].str.contains('FIELD GOAL')\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "df.loc[mask, 'PlayType'] = 'FIELD GOAL'\n",
    "\n",
    "mask = (df['PlayType'] == 'PASS') & df['Description'].str.contains('EXTRA POINT')\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "df.loc[mask, 'PlayType'] = 'EXTRA POINT'\n",
    "\n",
    "mask = (df['PlayType'] == 'PASS') & df['Description'].str.contains('KNEELS')\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "df.loc[mask, 'PlayType'] = 'QB KNEEL'\n",
    "\n",
    "mask = (df['PlayType'] == 'PASS') & df['Description'].str.contains('END GAME')\n",
    "df.loc[mask, 'PassType'] = 0\n",
    "df.loc[mask, 'PlayType'] = 'NO PLAY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'IsIncomplete' with 0\n",
    "mask = df['IsIncomplete'].isnull()\n",
    "df[mask] = df[mask].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace all of the null values in one faulty row with 0's\n",
    "mask = df['IsSack'].isnull()\n",
    "df[mask] = df[mask].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'IsMeasurement' with 0\n",
    "df['IsMeasurement'] = df['IsMeasurement'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract missing values of YardLineFixed from YardLine\n",
    "mask = df['YardLineFixed'].isnull()\n",
    "df.loc[mask, 'YardLineFixed'] = 100 - df[mask]['YardLine'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'IsNoPlay' with 0\n",
    "df['IsNoPlay'] = df['IsNoPlay'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'PenaltyYards' with 0\n",
    "df['PenaltyYards'] = df['PenaltyYards'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the rest and include description\n",
    "df.dropna(subset=['OffenseTeam', 'Description'], how='any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'Formation' with 0\n",
    "df['Formation'] = df['Formation'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correct mislabeled rush plays with the right RushDirection\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('CENTER'))\n",
    "df.loc[mask, 'RushDirection'] = 'CENTER'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('LEFT TACKLE'))\n",
    "df.loc[mask, 'RushDirection'] = 'LEFT TACKLE'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('RIGHT GUARD'))\n",
    "df.loc[mask, 'RushDirection'] = 'RIGHT GUARD'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('LEFT GUARD'))\n",
    "df.loc[mask, 'RushDirection'] = 'LEFT GUARD'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('RIGHT TACKLE'))\n",
    "df.loc[mask, 'RushDirection'] = 'RIGHT TACKLE'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('RIGHT END'))\n",
    "df.loc[mask, 'RushDirection'] = 'RIGHT END'\n",
    "\n",
    "mask = (df['RushDirection'].isnull()) & (df['PlayType'] == 'RUSH') & (df['Description'].str.contains('LEFT END'))\n",
    "df.loc[mask, 'RushDirection'] = 'LEFT END'\n",
    "\n",
    "# fill the rest with 0\n",
    "mask = df['RushDirection'].isnull()\n",
    "df[mask] = df[mask].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'PenaltyTeam' with 0\n",
    "df['PenaltyTeam'] = df['PenaltyTeam'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace null values of 'PenaltyType' with 0\n",
    "df['PenaltyType'] = df['PenaltyType'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn descriptions to unicode to be able to upload to mongodb\n",
    "# df['Description'] = df['Description'].apply(lambda x: unicode(x, 'utf-8', errors=\"ignore\"))\n",
    "\n",
    "# To upload data to mongodb, there are limits, will have to divy by team or season and upload to different tables\n",
    "# db_cilent = MongoClient()\n",
    "# db = db_cilent['NFL']\n",
    "# table = db['plays']\n",
    "# odo(df, db.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace offenseteam/defenseteam where 'SD' with 'LAC'\n",
    "mask = df['OffenseTeam'] == 'SD'\n",
    "df.loc[mask, 'OffenseTeam'] = 'LAC'\n",
    "\n",
    "mask = df['DefenseTeam'] == 'SD'\n",
    "df.loc[mask, 'DefenseTeam'] = 'LAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Team1_Team2 column to join weather data on\n",
    "def join_teams(values):\n",
    "    return \"_\".join(sorted(values))\n",
    "\n",
    "df['Team1_Team2'] = df[[u'OffenseTeam', u'DefenseTeam']].apply(join_teams, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import scraped weather data, clean, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../data/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn GameDate to datetime\n",
    "weather_df['GameDate'] = weather_df['GameDate'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change type from unicode to string\n",
    "weather_df['Team1_Team2'] = weather_df['Team1_Team2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop stadium, corrupt data\n",
    "weather_df = weather_df.drop('Stadium', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove '%' from humidity column\n",
    "weather_df['Humidity'] = weather_df['Humidity'].str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace visibility null values with visibility mean\n",
    "mask = weather_df['Visibility'].isnull()\n",
    "weather_df.loc[mask, 'Visibility'] = weather_df['Visibility'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace wind null values with wind mean\n",
    "mask = weather_df['Wind'].isnull()\n",
    "weather_df.loc[mask, 'Wind'] = weather_df['Wind'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace weather category null values with clear (mode)\n",
    "mask = weather_df['Weather_cat'].isnull()\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Clear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change grass subcategories to 'grass' value for surface feature\n",
    "mask = (weather_df['Surface'].isnull()) | (weather_df['Surface'] == 'Bermuda') | \\\n",
    "        (weather_df['Surface'] == 'Bluegrass') | (weather_df['Surface'] == 'Kentucky') | \\\n",
    "            (weather_df['Surface'] == 'Natural')\n",
    "    \n",
    "weather_df.loc[mask, 'Surface'] = 'Grass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change turf subcategories to 'Fieldturf' value for surface feature\n",
    "mask = (weather_df['Surface'] == 'A-Turf') | \\\n",
    "        (weather_df['Surface'] == 'UBU') | (weather_df['Surface'] == 'FieldTurf') | \\\n",
    "            (weather_df['Surface'] == 'RealGrass')\n",
    "    \n",
    "weather_df.loc[mask, 'Surface'] = 'Fieldturf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create major weather categories\n",
    "mask = weather_df['Weather_cat'].str.contains('Cloud')\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Cloudy'\n",
    "\n",
    "mask = weather_df['Weather_cat'].str.contains('Rain') | weather_df['Weather_cat'].str.contains('Drizzle') | \\\n",
    "        weather_df['Weather_cat'].str.contains('Showers') | weather_df['Weather_cat'].str.contains('storm')\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Rain'\n",
    "\n",
    "mask = weather_df['Weather_cat'].str.contains('Fair') | weather_df['Weather_cat'].str.contains('Clear') | \\\n",
    "        weather_df['Weather_cat'].str.contains('Sunny') | weather_df['Weather_cat'].str.contains('Dry') | \\\n",
    "            weather_df['Weather_cat'].str.contains('Breezy') | weather_df['Weather_cat'].str.contains('Humid')\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Clear'\n",
    "\n",
    "mask = weather_df['Weather_cat'].str.contains('Fog') | weather_df['Weather_cat'].str.contains('Overcast')\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Overcast' \n",
    "\n",
    "mask = weather_df['Weather_cat'].str.contains('Snow') | weather_df['Weather_cat'].str.contains('Wintry Mix') | \\\n",
    "        weather_df['Weather_cat'].str.contains('Flurries')\n",
    "weather_df.loc[mask, 'Weather_cat'] = 'Snow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge original df with weather df\n",
    "combined_df = pd.merge(df, weather_df, how='left', left_on = ['GameDate', 'Team1_Team2'], right_on = ['GameDate', 'Team1_Team2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering, add scraped coach data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create columns to keep track of scoring plays. Will be used to calculate scores\n",
    "mask = (combined_df['Description'].str.contains('TOUCHDOWN')) | (combined_df['IsTouchdown'] == 1)\n",
    "combined_df['IsTouchdown'] = np.where(mask, 1, 0)\n",
    "\n",
    "mask_2 = combined_df['Description'].str.contains('FIELD GOAL IS GOOD')\n",
    "combined_df['IsFieldGoal'] = np.where(mask_2, 1, 0)\n",
    "\n",
    "mask_3 = combined_df['Description'].str.contains('EXTRA POINT IS GOOD')\n",
    "combined_df['IsExtraPoint'] = np.where(mask_3, 1, 0)\n",
    "\n",
    "mask_4 = ((combined_df['Description'].str.contains('TWO-POINT CONVERSION')) & (combined_df['Description'].str.contains('ATTEMPT SUCCEEDS'))) | (combined_df['IsTwoPointConversionSuccessful'] == 1)\n",
    "combined_df['IsTwoPointConversionScore'] = np.where(mask_4, 1, 0)\n",
    "\n",
    "mask_5 = combined_df['Description'].str.contains('SAFETY')\n",
    "combined_df['IsSafety'] = np.where(mask_5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new columns to assign score values on scoring plays\n",
    "combined_df['IsHome'] = np.where(combined_df['Home_team'] == combined_df['OffenseTeam'], 1, 0)\n",
    "combined_df['Home_score'] = 0\n",
    "combined_df['Away_score'] = 0\n",
    "\n",
    "mask_home = (combined_df['IsTouchdown'] == 1) & (combined_df['IsHome'] == 1)\n",
    "combined_df.loc[mask_home, 'Home_score'] = 6\n",
    "mask_away = (combined_df['IsTouchdown'] == 1) & (combined_df['IsHome'] == 0)\n",
    "combined_df.loc[mask_away, 'Away_score'] = 6\n",
    "\n",
    "mask_home = (combined_df['IsFieldGoal'] == 1) & (combined_df['IsHome'] == 1)\n",
    "combined_df.loc[mask_home, 'Home_score'] = 3\n",
    "mask_away = (combined_df['IsFieldGoal'] == 1) & (combined_df['IsHome'] == 0)\n",
    "combined_df.loc[mask_away, 'Away_score'] = 3\n",
    "\n",
    "mask_home = (combined_df['IsExtraPoint'] == 1) & (combined_df['IsHome'] == 1)\n",
    "combined_df.loc[mask_home, 'Home_score'] = 1\n",
    "mask_away = (combined_df['IsExtraPoint'] == 1) & (combined_df['IsHome'] == 0)\n",
    "combined_df.loc[mask_away, 'Away_score'] = 1\n",
    "\n",
    "mask_home = (combined_df['IsTwoPointConversionScore'] == 1) & (combined_df['IsHome'] == 1)\n",
    "combined_df.loc[mask_home, 'Home_score'] = 2\n",
    "mask_away = (combined_df['IsTwoPointConversionScore'] == 1) & (combined_df['IsHome'] == 0)\n",
    "combined_df.loc[mask_away, 'Away_score'] = 2\n",
    "\n",
    "mask_home = (combined_df['IsSafety'] == 1) & (combined_df['IsHome'] == 1)\n",
    "combined_df.loc[mask_home, 'Home_score'] = 2\n",
    "mask_away = (combined_df['IsSafety'] == 1) & (combined_df['IsHome'] == 0)\n",
    "combined_df.loc[mask_away, 'Away_score'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge df with coach data. Had to keep them separate to make sure offensive/defensive \n",
    "# coaches/coordinators are associated with the appropriate plays\n",
    "off_df = pd.read_csv('../data/offensive_coach_data.csv')\n",
    "def_df = pd.read_csv('../data/defensive_coach_data.csv')\n",
    "\n",
    "off_df['SeasonYear'] = off_df['SeasonYear'].astype(float)\n",
    "def_df['SeasonYear'] = off_df['SeasonYear'].astype(float)\n",
    "new_combined_df = pd.merge(combined_df, off_df, how='left', left_on=['SeasonYear', 'OffenseTeam'], right_on=['SeasonYear', 'OffenseTeam'])\n",
    "new_combined_df = pd.merge(new_combined_df, def_df, how='left', left_on=['SeasonYear', 'DefenseTeam'], right_on=['SeasonYear', 'DefenseTeam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With the previously created Home_score/Away_score features, \n",
    "# calculate running totals for all plays. Sort by quarter, minute, second.\n",
    "# Additionally, add feature Last_play and Two_plays_ago\n",
    "new_combined_df['Home_total_score'] = None\n",
    "new_combined_df['Away_total_score'] = None\n",
    "new_combined_df['Last_play'] = None\n",
    "\n",
    "unique_games = new_combined_df['GameId'].unique()\n",
    "for game in unique_games:\n",
    "    mask = new_combined_df['GameId'] == game\n",
    "    game_df = new_combined_df[mask]\n",
    "    game_df = game_df.sort_values([u'Quarter', u'Minute', u'Second'])\n",
    "    \n",
    "    team1, team2 = game_df['OffenseTeam'].unique()\n",
    "    team1_plays = (game_df['OffenseTeam'] == team1) & (game_df['Down'] != 0)\n",
    "    team2_plays = (game_df['OffenseTeam'] == team2) & (game_df['Down'] != 0)\n",
    "    \n",
    "    new_combined_df.loc[mask, 'Home_total_score'] = game_df['Home_score'].cumsum()\n",
    "    new_combined_df.loc[mask, 'Away_total_score'] = game_df['Away_score'].cumsum()\n",
    "    new_combined_df.loc[mask & team1_plays, 'Last_play'] = game_df[team1_plays]['PlayType'].shift(1)\n",
    "    new_combined_df.loc[mask & team2_plays, 'Last_play'] = game_df[team2_plays]['PlayType'].shift(1)\n",
    "    new_combined_df.loc[mask & team1_plays, 'Two_plays_ago'] = game_df[team1_plays]['PlayType'].shift(2)\n",
    "    new_combined_df.loc[mask & team2_plays, 'Two_plays_ago'] = game_df[team2_plays]['PlayType'].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Score_differential to capture current leads and deficits\n",
    "new_combined_df['Score_differential'] = 0\n",
    "\n",
    "mask = new_combined_df['IsHome'] == 1\n",
    "new_combined_df.loc[mask, 'Score_differential'] = new_combined_df['Home_total_score'] - new_combined_df['Away_total_score']\n",
    "\n",
    "mask = new_combined_df['IsHome'] == 0\n",
    "new_combined_df.loc[mask, 'Score_differential'] = new_combined_df['Away_total_score'] - new_combined_df['Home_total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create features Last_play_IsPass, Last_two_plays_IsPass (0,1,2)\n",
    "last_pass_mask = new_combined_df['Last_play'] == 'PASS'\n",
    "new_combined_df['Last_play_IsPass'] = np.where(last_pass_mask, 1, 0)\n",
    "\n",
    "new_combined_df['Last_two_plays_IsPass'] = 0\n",
    "two_pass_mask = (last_pass_mask) & (new_combined_df['Two_plays_ago'] == 'PASS')\n",
    "new_combined_df.loc[two_pass_mask, 'Last_two_plays_IsPass'] = 2\n",
    "\n",
    "one_pass_mask = (last_pass_mask) & (new_combined_df['Two_plays_ago'] != 'PASS')\n",
    "new_combined_df.loc[one_pass_mask, 'Last_two_plays_IsPass'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make new features, left_in_half , left_in_game (both in seconds)\n",
    "new_combined_df['Left_in_game'] = 3600 - (((new_combined_df['Quarter'] - 1) * 900) + (new_combined_df['Minute'] * 60) + new_combined_df['Second'])\n",
    "\n",
    "first_half_mask = (new_combined_df['Quarter'] == 1) | (new_combined_df['Quarter'] == 2)\n",
    "new_combined_df.loc[first_half_mask, 'Left_in_half'] = 1800 - (((new_combined_df['Quarter'] - 1) * 900) + (new_combined_df['Minute'] * 60) + new_combined_df['Second'])\n",
    "\n",
    "second_half_mask = (new_combined_df['Quarter'] == 3) | (new_combined_df['Quarter'] == 4) | (new_combined_df['Quarter'] == 5)\n",
    "new_combined_df.loc[second_half_mask, 'Left_in_half'] = new_combined_df['Left_in_game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract month from gamedate\n",
    "new_combined_df['Month'] = new_combined_df['GameDate'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn features into string format to dummify\n",
    "new_combined_df['SeasonYear'] = new_combined_df['SeasonYear'].astype(int).astype(str)\n",
    "new_combined_df['Quarter'] = new_combined_df['Quarter'].astype(str)\n",
    "new_combined_df['Down'] = new_combined_df['Down'].astype(str)\n",
    "new_combined_df['Month'] = new_combined_df['Month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_combined_df.to_csv('../data/master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
